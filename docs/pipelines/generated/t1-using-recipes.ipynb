{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f72a83",
   "metadata": {},
   "source": [
    "> The most common usage of `hover` is through built-in `recipe`s like in the quickstart.\n",
    ">\n",
    "> :ferris_wheel: Let's explore another `recipe` -- an active learning example.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Fundamentals**\n",
    "\n",
    "Hover `recipe`s are functions that take a `SupervisableDataset` and return an annotation interface.\n",
    "\n",
    "The `SupervisableDataset` is assumed to have some data and embeddings.\n",
    "\n",
    "## **Recap: Data & Embeddings**\n",
    "\n",
    "Let's preprare a dataset with embeddings. This is almost the same as in the [quickstart](../t0-quickstart/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87a493d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T02:04:54.502575Z",
     "iopub.status.busy": "2023-06-27T02:04:54.502173Z",
     "iopub.status.idle": "2023-06-27T02:04:57.129687Z",
     "shell.execute_reply": "2023-06-27T02:04:57.129038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">356</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m356\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">382</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m382\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m98\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m97\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "raw_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "train_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_train.csv\"\n",
    "\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(raw_csv_path).sample(400)\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "df_train = pd.read_csv(train_csv_path).sample(400)\n",
    "df_train[\"SUBSET\"] = \"train\"\n",
    "df_dev = pd.read_csv(train_csv_path).sample(100)\n",
    "df_dev[\"SUBSET\"] = \"dev\"\n",
    "df_test = pd.read_csv(train_csv_path).sample(100)\n",
    "df_test[\"SUBSET\"] = \"test\"\n",
    "\n",
    "# build overall dataframe and ensure feature type\n",
    "df = pd.concat([df_raw, df_train, df_dev, df_test])\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df, feature_key=\"text\", label_key=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9efa5c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83e40b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T02:04:57.133177Z",
     "iopub.status.busy": "2023-06-27T02:04:57.132506Z",
     "iopub.status.idle": "2023-06-27T02:05:00.060829Z",
     "shell.execute_reply": "2023-06-27T02:05:00.060227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Yes, there are serveral programs which can convert font files (eq the Borland fonts) to objects consisting of spheres, cones etc.  I've used a program (forgot its name/place, but i can look for it) which converted these Borland fonts to three different raytracers. Vivid, POV and Polyray (which i like more (more flexibel/faster/use of expressions etc). The program has a lot nice features. So if interested give me a mail.\n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"]().loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5d365",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e21c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T02:05:00.064236Z",
     "iopub.status.busy": "2023-06-27T02:05:00.063560Z",
     "iopub.status.idle": "2023-06-27T02:05:22.246106Z",
     "shell.execute_reply": "2023-06-27T02:05:22.245460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 933/933 [00:02<00:00, 404.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">836</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m836\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/runner/work/hover/hover/.tox/test_notebook_generation/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m97\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a374a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Recipe-Specific Ingredient**\n",
    "\n",
    "Each recipe has different functionalities and potentially different signature.\n",
    "\n",
    "To utilize active learning, we need to specify how to get a model in the loop.\n",
    "\n",
    "`hover` considers the `vectorizer` as a \"frozen\" embedding and follows up with a neural network, which infers its own dimensionality from the vectorizer and the output classes.\n",
    "\n",
    "-   This architecture named [`VectorNet`](../../reference/core-neural/#hover.core.neural.VectorNet) is the (default) basis of active learning in `hover`.\n",
    "\n",
    "-   <details open><summary>Custom models</summary>\n",
    "    It is possible to use a model other than `VectorNet` or its subclass.\n",
    "\n",
    "    You will need to implement the following methods with the same signatures as `VectorNet`:\n",
    "\n",
    "    -   [`train`](../../reference/core-neural/#hover.core.neural.VectorNet.train)\n",
    "    -   [`save`](../../reference/core-neural/#hover.core.neural.VectorNet.save)\n",
    "    -   [`predict_proba`](../../reference/core-neural/#hover.core.neural.VectorNet.predict_proba)\n",
    "    -   [`prepare_loader`](../../reference/core-neural/#hover.core.neural.VectorNet.prepare_loader)\n",
    "    -   [`manifold_trajectory`](../../reference/core-neural/#hover.core.neural.VectorNet.manifold_trajectory)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2435fd79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T02:05:22.250829Z",
     "iopub.status.busy": "2023-06-27T02:05:22.249431Z",
     "iopub.status.idle": "2023-06-27T02:05:22.268752Z",
     "shell.execute_reply": "2023-06-27T02:05:22.268072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ VectorNet: reset neural net: in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span><span style=\"color: #008000; text-decoration-color: #008000\"> out </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ VectorNet: reset neural net: in \u001b[0m\u001b[1;36m300\u001b[0m\u001b[32m out \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ VectorNet: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ VectorNet: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0584425e-02 8.6821365e-04 9.9132699e-04 8.3235487e-02 1.0322960e-02\n",
      " 1.3993829e-03 2.7361966e-03 1.6139956e-02 1.5453859e-01 5.0758380e-03\n",
      " 2.6182527e-02 8.0104847e-04 4.7740523e-02 7.6309522e-04 4.8751354e-02\n",
      " 7.5871916e-04 4.4566849e-03 1.8890903e-04 5.7277906e-01 1.6857371e-03]\n",
      "[[2.0584425e-02 8.6821365e-04 9.9132699e-04 8.3235487e-02 1.0322960e-02\n",
      "  1.3993829e-03 2.7361966e-03 1.6139956e-02 1.5453859e-01 5.0758380e-03\n",
      "  2.6182527e-02 8.0104847e-04 4.7740523e-02 7.6309522e-04 4.8751354e-02\n",
      "  7.5871916e-04 4.4566849e-03 1.8890903e-04 5.7277906e-01 1.6857371e-03]]\n"
     ]
    }
   ],
   "source": [
    "from hover.core.neural import VectorNet\n",
    "from hover.utils.common_nn import LogisticRegression\n",
    "\n",
    "# Create a model with vectorizer-NN architecture.\n",
    "# model.pt will point to a PyTorch state dict (to be created)\n",
    "# the label classes in the dataset can change, and vecnet can adjust to that\n",
    "vecnet = VectorNet(vectorizer, LogisticRegression, \"model.pt\", dataset.classes)\n",
    "\n",
    "# predict_proba accepts individual strings or list\n",
    "# text -> vector -> class probabilities\n",
    "# if no classes right now, will see an empty list\n",
    "print(vecnet.predict_proba(text))\n",
    "print(vecnet.predict_proba([text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd50289",
   "metadata": {},
   "source": [
    "Note how the callback dynamically takes `dataset.classes`, which means the model architecture will adapt when we add classes during annotation.\n",
    "\n",
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "Now we invoke the `active_learning` recipe.\n",
    "\n",
    "-   <details open><summary>Tips: how recipes work programmatically</summary>\n",
    "    In general, a `recipe` is a function taking a `SupervisableDataset` and other arguments based on its functionality.\n",
    "\n",
    "    Here are a few common recipes:\n",
    "\n",
    "    === \"active_learning\"\n",
    "\n",
    "        ::: hover.recipes.experimental.active_learning\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"simple_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.simple_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"linked_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.linked_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    The recipe returns a `handle` function which `bokeh` can use to visualize an annotation interface in multiple settings.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b16196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-27T02:05:22.271469Z",
     "iopub.status.busy": "2023-06-27T02:05:22.271257Z",
     "iopub.status.idle": "2023-06-27T02:05:22.350571Z",
     "shell.execute_reply": "2023-06-27T02:05:22.349670Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.experimental import active_learning\n",
    "\n",
    "interactive_plot = active_learning(dataset, vecnet)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2bcfea",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface with multiple plots</summary>\n",
    "    <details open><summary>Video guide: leveraging linked selection</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TIwBlCH9YHw\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Video guide: active learning</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hRIn3r7ovQ8\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide: active learning</summary>\n",
    "        Inspecting model predictions allows us to\n",
    "\n",
    "        -   get an idea of how the current set of annotations will likely teach the model.\n",
    "        -   locate the most valuable samples for further annotation.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
