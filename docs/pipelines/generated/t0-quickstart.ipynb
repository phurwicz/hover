{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871e91d5",
   "metadata": {},
   "source": [
    "> Welcome to the basic use case of `hover`!\n",
    ">\n",
    "> :sunglasses: Let's say we want to label some data and call it a day.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 1 / 3: Raw Data**\n",
    "\n",
    "Start with a spreadsheet loaded in `pandas`.\n",
    "\n",
    "We turn it into a [`SupervisableDataset`](../../reference/core-dataset/#hover.core.dataset.SupervisableDataset) designed for labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fac01d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:19:26.245651Z",
     "iopub.status.busy": "2024-01-30T01:19:26.245453Z",
     "iopub.status.idle": "2024-01-30T01:19:27.543004Z",
     "shell.execute_reply": "2024-01-30T01:19:27.542390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">975</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m1000\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m975\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[In response to some of the discussions on the...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am working on a problem of scheduling classr...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok all you trivia buffs, I have a good one for...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi...  I need information on scaring. Particul...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So I should be very comfortable that 500,0...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label\n",
       "0  [In response to some of the discussions on the...    raw  ABSTAIN\n",
       "1  I am working on a problem of scheduling classr...    raw  ABSTAIN\n",
       "2  Ok all you trivia buffs, I have a good one for...    raw  ABSTAIN\n",
       "3  Hi...  I need information on scaring. Particul...    raw  ABSTAIN\n",
       "4      So I should be very comfortable that 500,0...    raw  ABSTAIN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "example_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(example_csv_path).sample(1000)\n",
    "df_raw[\"text\"] = df_raw[\"text\"].astype(str)\n",
    "\n",
    "# data is divided into 4 subsets: \"raw\" / \"train\" / \"dev\" / \"test\"\n",
    "# this example assumes no labeled data available., i.e. only \"raw\"\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df_raw, feature_key=\"text\", label_key=\"label\")\n",
    "\n",
    "# each subset can be accessed as its own DataFrame\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d74d0",
   "metadata": {},
   "source": [
    "-   <details open><summary>FAQ</summary>\n",
    "    <details open><summary>What if I have multiple features?</summary>\n",
    "        `feature_key` refers to the field that will be vectorized later on, which can be a JSON that encloses multiple features.\n",
    "\n",
    "        For example, suppose our data entries look like this:\n",
    "```python\n",
    "        {\"f1\": \"foo\", \"f2\": \"bar\", \"non_feature\": \"abc\"}\n",
    "```\n",
    "\n",
    "        We can put `f1` and `f2` in a JSON and convert the entries like this:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Can I use audio or image data?</summary>\n",
    "        Yes! Please check out the \"Guides\" section of the documentation.\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 2 / 3: Embedding**\n",
    "\n",
    "A pre-trained embedding lets us group data points semantically.\n",
    "\n",
    "In particular, let's define a `data -> embedding vector` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ab3147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:19:27.545710Z",
     "iopub.status.busy": "2024-01-30T01:19:27.545446Z",
     "iopub.status.idle": "2024-01-30T01:19:30.466914Z",
     "shell.execute_reply": "2024-01-30T01:19:30.466096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: [In response to some of the discussions on the Sabbath, Andrew Byler commented that if we really followed sola scriptura we would worship on Saturday -- the change to Sunday was a law made by the Church, and we don't acknowledge its authority to make laws.  I noted that Protestants do not consider Sunday worship a law.  --clh]  He was not referring to the FAQ but to the five Sabbath Admissions posted on the bible study group.  This is what prompted someone to send the FAQ to me.  n> ceremonial law is not binding on Christians.  You cannot show, from scripture, that the weekly Sabbath is part of the ceremonial laws.   Before you post a text in reply investigate its context.  Can the churches also decide what is and is not sin?  Interesting.  Where there is no divine imperative of course we must establish rules of operation.  But we cannot be as creative with what God has explicitly spoken on.  Darius\n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"]().loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5bb2b4",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips</summary>\n",
    "    <details open><summary>Caching</summary>\n",
    "        `dataset` by itself stores the original features but not the corresponding vectors.\n",
    "\n",
    "        To avoid vectorizing the same feature again and again, we could simply do:\n",
    "```python\n",
    "        from functools import cache\n",
    "\n",
    "        @cache\n",
    "        def vectorizer(feature):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        If you'd like to limit the size of the cache, something like `@lru_cache(maxsize=10000)` could help.\n",
    "\n",
    "        Check out [functools](https://docs.python.org/3/library/functools.html) for more options.\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Vectorizing multiple features</summary>\n",
    "        Suppose we have multiple features enclosed in a JSON:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "        Also, suppose we have individual vectorizers likes this:\n",
    "```python\n",
    "        def vectorizer_1(feature_1):\n",
    "            # put code here\n",
    "\n",
    "        def vectorizer_2(feature_2):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        Then we can define a composite vectorizer:\n",
    "```python\n",
    "        import json\n",
    "        import numpy as np\n",
    "\n",
    "        def vectorizer(feature_json):\n",
    "            data_dict = json.loads(feature_json)\n",
    "            vectors = []\n",
    "            for field, func in [\n",
    "                (\"f1\", vectorizer_1),\n",
    "                (\"f2\", vectorizer_2),\n",
    "            ]:\n",
    "                vectors.append(func(data_dict[field]))\n",
    "\n",
    "            return np.concatenate(vectors)\n",
    "```\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 3 / 3: 2D Embedding**\n",
    "\n",
    "We compute a 2D version of the pre-trained embedding to visualize the whole dataset.\n",
    "\n",
    "Hover has built-in methods for calling [umap](https://umap-learn.readthedocs.io/en/latest/) or [ivis](https://bering-ivis.readthedocs.io/en/latest/).\n",
    "\n",
    "-   <details open><summary>Dependencies (when in your own environment)</summary>\n",
    "    The libraries for this step are not directly required by `hover`:\n",
    "\n",
    "    -   for umap: `pip install umap-learn`\n",
    "    -   for ivis: `pip install ivis[cpu]` or `pip install ivis[gpu]`\n",
    "\n",
    "    `umap-learn` is installed in this demo environment.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b64c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:19:30.469879Z",
     "iopub.status.busy": "2024-01-30T01:19:30.469597Z",
     "iopub.status.idle": "2024-01-30T01:19:53.620524Z",
     "shell.execute_reply": "2024-01-30T01:19:53.619940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:   0%|          | 0/975 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:   4%|â–         | 37/975 [00:00<00:02, 339.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:   8%|â–Š         | 80/975 [00:00<00:02, 386.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  13%|â–ˆâ–Ž        | 124/975 [00:00<00:02, 392.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  17%|â–ˆâ–‹        | 164/975 [00:00<00:02, 348.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  22%|â–ˆâ–ˆâ–       | 212/975 [00:00<00:02, 299.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  28%|â–ˆâ–ˆâ–Š       | 270/975 [00:00<00:01, 372.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 342/975 [00:00<00:01, 465.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 410/975 [00:00<00:01, 524.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 466/975 [00:01<00:01, 328.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 534/975 [00:01<00:01, 398.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 600/975 [00:01<00:00, 387.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 647/975 [00:01<00:00, 404.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 697/975 [00:01<00:00, 426.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 774/975 [00:01<00:00, 377.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 851/975 [00:02<00:00, 458.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 913/975 [00:02<00:00, 494.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Vectorizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 975/975 [00:02<00:00, 426.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">975</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m975\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_2d_0</th>\n",
       "      <th>embed_2d_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[In response to some of the discussions on the...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>15.757908</td>\n",
       "      <td>0.144990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am working on a problem of scheduling classr...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>15.881067</td>\n",
       "      <td>4.044128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok all you trivia buffs, I have a good one for...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>11.522151</td>\n",
       "      <td>0.113648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi...  I need information on scaring. Particul...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>14.249089</td>\n",
       "      <td>2.176209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So I should be very comfortable that 500,0...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>15.890726</td>\n",
       "      <td>1.715243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label  \\\n",
       "0  [In response to some of the discussions on the...    raw  ABSTAIN   \n",
       "1  I am working on a problem of scheduling classr...    raw  ABSTAIN   \n",
       "2  Ok all you trivia buffs, I have a good one for...    raw  ABSTAIN   \n",
       "3  Hi...  I need information on scaring. Particul...    raw  ABSTAIN   \n",
       "4      So I should be very comfortable that 500,0...    raw  ABSTAIN   \n",
       "\n",
       "   embed_2d_0  embed_2d_1  \n",
       "0   15.757908    0.144990  \n",
       "1   15.881067    4.044128  \n",
       "2   11.522151    0.113648  \n",
       "3   14.249089    2.176209  \n",
       "4   15.890726    1.715243  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)\n",
    "\n",
    "# what we did adds 'embed_2d_0' and 'embed_2d_1' columns to the DataFrames in dataset.dfs\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57dacb",
   "metadata": {},
   "source": [
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "We are ready for the annotation interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d753ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T01:19:53.623583Z",
     "iopub.status.busy": "2024-01-30T01:19:53.623076Z",
     "iopub.status.idle": "2024-01-30T01:19:53.706792Z",
     "shell.execute_reply": "2024-01-30T01:19:53.706221Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.stable import simple_annotator\n",
    "\n",
    "interactive_plot = simple_annotator(dataset)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d45b39",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface basics</summary>\n",
    "    <details open><summary>Video guide</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WYN2WduzJWg\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide</summary>\n",
    "        There should be a `SupervisableDataset` board on the left and an `BokehDataAnnotator` on the right, each with a few buttons.\n",
    "\n",
    "        === \"SupervisableDataset\"\n",
    "            -   `push`: push `Dataset` updates to the bokeh plots.\n",
    "            -   `commit`: add data entries selected in the `Annotator` to a specified subset.\n",
    "            -   `dedup`: deduplicate across subsets by `feature` (last in gets kept).\n",
    "            -   `export`: save your data (all subsets) in a specified format.\n",
    "\n",
    "        === \"BokehDataAnnotator\"\n",
    "            -   `raw`/`train`/`dev`/`test`: choose which subsets to display or hide.\n",
    "            -   `apply`: apply the `label` input to the selected points in the `raw` subset only.\n",
    "\n",
    "        We've essentially put the data into neighborboods based on the vectorizer, but the quality (homogeneity of labels) of such neighborhoods can vary.\n",
    "\n",
    "        -   hover over any data point to see its tooltip.\n",
    "        -   take advantage of different selection tools to apply labels at appropriate scales.\n",
    "        -   the search widget might turn out useful.\n",
    "            -    note that it does not select points but highlights them.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
