{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2fca52",
   "metadata": {},
   "source": [
    "> Welcome to the basic use case of `hover`!\n",
    ">\n",
    "> :sunglasses: Let's say we want to label some data and call it a day.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 1 / 3: Raw Data**\n",
    "\n",
    "Start with a spreadsheet loaded in `pandas`.\n",
    "\n",
    "We turn it into a [`SupervisableDataset`](../../reference/core-dataset/#hover.core.dataset.SupervisableDataset) designed for labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef3791f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T01:25:17.112783Z",
     "iopub.status.busy": "2023-12-05T01:25:17.112589Z",
     "iopub.status.idle": "2023-12-05T01:25:18.955390Z",
     "shell.execute_reply": "2023-12-05T01:25:18.954706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">984</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m1000\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m984\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m0\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: finished setting up bokeh elements.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tcpview is the result of several problems we h...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're right: Thomas, Gonzalez, Sheffield, an...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Um, I hate to break this to you, but article ...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, there's no evidence that would convince ...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dillon comments that Space Food Sticks may hav...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label\n",
       "0  Tcpview is the result of several problems we h...    raw  ABSTAIN\n",
       "1   You're right: Thomas, Gonzalez, Sheffield, an...    raw  ABSTAIN\n",
       "2   Um, I hate to break this to you, but article ...    raw  ABSTAIN\n",
       "3    No, there's no evidence that would convince ...    raw  ABSTAIN\n",
       "4  dillon comments that Space Food Sticks may hav...    raw  ABSTAIN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "example_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(example_csv_path).sample(1000)\n",
    "df_raw[\"text\"] = df_raw[\"text\"].astype(str)\n",
    "\n",
    "# data is divided into 4 subsets: \"raw\" / \"train\" / \"dev\" / \"test\"\n",
    "# this example assumes no labeled data available., i.e. only \"raw\"\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df_raw, feature_key=\"text\", label_key=\"label\")\n",
    "\n",
    "# each subset can be accessed as its own DataFrame\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786dfd1",
   "metadata": {},
   "source": [
    "-   <details open><summary>FAQ</summary>\n",
    "    <details open><summary>What if I have multiple features?</summary>\n",
    "        `feature_key` refers to the field that will be vectorized later on, which can be a JSON that encloses multiple features.\n",
    "\n",
    "        For example, suppose our data entries look like this:\n",
    "```python\n",
    "        {\"f1\": \"foo\", \"f2\": \"bar\", \"non_feature\": \"abc\"}\n",
    "```\n",
    "\n",
    "        We can put `f1` and `f2` in a JSON and convert the entries like this:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Can I use audio or image data?</summary>\n",
    "        Yes! Please check out the \"Guides\" section of the documentation.\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 2 / 3: Embedding**\n",
    "\n",
    "A pre-trained embedding lets us group data points semantically.\n",
    "\n",
    "In particular, let's define a `data -> embedding vector` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4997e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T01:25:18.958350Z",
     "iopub.status.busy": "2023-12-05T01:25:18.957929Z",
     "iopub.status.idle": "2023-12-05T01:25:21.732005Z",
     "shell.execute_reply": "2023-12-05T01:25:21.731333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Tcpview is the result of several problems we had at UW.  We have several Network General Sniffers which are heavily used to help debug problems on several hundred subnets. These are good tools, but they are 1) heavy,  2) hard to find when you need one, 3) limited in their software expandibility, 4) difficult to use to upload data for analysis, 5) cannot be remotely operated, and 6) cannot resolve names with DNS, requiring much manual  manipulation of the name table.  We also sometimes use tcpdump, but we found  it 1) too difficult for most people, 2) did not have enough information for many protocols, 3) could not be used interactively, 4) could not handle TCP streams and 5) could not read Sniffer files.  However, tcpdump did do a reasonable job of decoding a large number of protocols, and could be easily modified.  Tcpview is an attempt to resolve these problems by adding a Motif interface to tcpdump and expanding its features.  Tcpview has been tested on a DECstation 5000 and Sun 4 under Ultrix 4.2 and SunOS 4.1 respectively.  It should work on the same systems as tcpdump. It compiles with cc and gcc on the DEC and Sun.  To build tcpview you will need Motif 1.1 or better.  The following files are available for anonymous ftp from  ftp.cac.washington.edu in /pub/networking  tcpview-1.0.tar.Z tcpview and tcpdump source code tcpview-1.0.sun.tar.Z Sun4 binaries tcpview-1.0.dec.tar.Z DEC Mips Ultrix 4.2 binaries  What tcpview adds to tcpdump: - easier interface - enhanced protocol decoding - hex display of frame - capture based on time, number of frames, or user interrupt - can show ethernet addresses with manufacturer's name - ethernet address host table - can easily follow a stream, highlighting out-of-order frames - can send TCP data to an external file or filter for additional  processing.  ------------------------------------------------------------------------------- CHANGES TO TCPDUMP 2.2.1  New features:  Now reads and writes Network General Sniffer files.  When used with '-r', the  file type will be automatically detected.  Can now read in (and use) an SNMP MIB file.  The hex format has been changed.  New time options have been added.  Options were added to allow viewing and processing of the data in TCP packets.  Bugs were fixed in the relative TCP sequence numbers. (-S flag)  New flags: -R read Sniffer file.  Not usually needed, except for reading from stdin -ttt prints delta times -tttt prints times relative to the first frame -W write a Sniffer save file (use with -w) -x print frame (minus link-level header) in hexdump format.    Sample output:  16:36:23.349851 jeff.cac.washington.edu.1285 > nic.funet.fi.ftp: S 0:0(0) win 16384         0000  45 00 00 28 8a 98 00 00 3c 06 7c 9c 80 5f 70 02   |  E..(....<.|.._p.         0010  80 d6 06 64 05 05 00 15 5b 19 4a 00 00 00 00 00   |  ...d....[.J.....         0020  50 02 40 00 4e 13 00 00 00 00 00 00 00 00         |  P.@.N.........  -X print TCP data in hexdump format (used with -Z) -z write TCP data to stdout (use with -t to eliminate timestamp) -Z write frames and TCP data to stdout   Martin M. Hunt martinh@cac.washington.edu Networks & Distributed Computing University of Washington       -- \n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"]().loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df67c1",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips</summary>\n",
    "    <details open><summary>Caching</summary>\n",
    "        `dataset` by itself stores the original features but not the corresponding vectors.\n",
    "\n",
    "        To avoid vectorizing the same feature again and again, we could simply do:\n",
    "```python\n",
    "        from functools import cache\n",
    "\n",
    "        @cache\n",
    "        def vectorizer(feature):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        If you'd like to limit the size of the cache, something like `@lru_cache(maxsize=10000)` could help.\n",
    "\n",
    "        Check out [functools](https://docs.python.org/3/library/functools.html) for more options.\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Vectorizing multiple features</summary>\n",
    "        Suppose we have multiple features enclosed in a JSON:\n",
    "```python\n",
    "        # could also keep f1 and f2 around\n",
    "        {'feature': '{\"f1\": \"foo\", \"f2\": \"bar\"}', 'non_feature': 'abc'}\n",
    "```\n",
    "\n",
    "        Also, suppose we have individual vectorizers likes this:\n",
    "```python\n",
    "        def vectorizer_1(feature_1):\n",
    "            # put code here\n",
    "\n",
    "        def vectorizer_2(feature_2):\n",
    "            # put code here\n",
    "```\n",
    "\n",
    "        Then we can define a composite vectorizer:\n",
    "```python\n",
    "        import json\n",
    "        import numpy as np\n",
    "\n",
    "        def vectorizer(feature_json):\n",
    "            data_dict = json.loads(feature_json)\n",
    "            vectors = []\n",
    "            for field, func in [\n",
    "                (\"f1\", vectorizer_1),\n",
    "                (\"f2\", vectorizer_2),\n",
    "            ]:\n",
    "                vectors.append(func(data_dict[field]))\n",
    "\n",
    "            return np.concatenate(vectors)\n",
    "```\n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Ingredient 3 / 3: 2D Embedding**\n",
    "\n",
    "We compute a 2D version of the pre-trained embedding to visualize the whole dataset.\n",
    "\n",
    "Hover has built-in methods for calling [umap](https://umap-learn.readthedocs.io/en/latest/) or [ivis](https://bering-ivis.readthedocs.io/en/latest/).\n",
    "\n",
    "-   <details open><summary>Dependencies (when in your own environment)</summary>\n",
    "    The libraries for this step are not directly required by `hover`:\n",
    "\n",
    "    -   for umap: `pip install umap-learn`\n",
    "    -   for ivis: `pip install ivis[cpu]` or `pip install ivis[gpu]`\n",
    "\n",
    "    `umap-learn` is installed in this demo environment.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa975b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T01:25:21.734896Z",
     "iopub.status.busy": "2023-12-05T01:25:21.734410Z",
     "iopub.status.idle": "2023-12-05T01:25:44.337428Z",
     "shell.execute_reply": "2023-12-05T01:25:44.336840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 984/984 [00:02<00:00, 416.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">984</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m984\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m0\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_2d_0</th>\n",
       "      <th>embed_2d_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tcpview is the result of several problems we h...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>-0.115253</td>\n",
       "      <td>1.609969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're right: Thomas, Gonzalez, Sheffield, an...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>-4.440539</td>\n",
       "      <td>1.212615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Um, I hate to break this to you, but article ...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>-4.412233</td>\n",
       "      <td>-0.612158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, there's no evidence that would convince ...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>-5.483528</td>\n",
       "      <td>0.927831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dillon comments that Space Food Sticks may hav...</td>\n",
       "      <td>raw</td>\n",
       "      <td>ABSTAIN</td>\n",
       "      <td>-5.713274</td>\n",
       "      <td>1.065829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text SUBSET    label  \\\n",
       "0  Tcpview is the result of several problems we h...    raw  ABSTAIN   \n",
       "1   You're right: Thomas, Gonzalez, Sheffield, an...    raw  ABSTAIN   \n",
       "2   Um, I hate to break this to you, but article ...    raw  ABSTAIN   \n",
       "3    No, there's no evidence that would convince ...    raw  ABSTAIN   \n",
       "4  dillon comments that Space Food Sticks may hav...    raw  ABSTAIN   \n",
       "\n",
       "   embed_2d_0  embed_2d_1  \n",
       "0   -0.115253    1.609969  \n",
       "1   -4.440539    1.212615  \n",
       "2   -4.412233   -0.612158  \n",
       "3   -5.483528    0.927831  \n",
       "4   -5.713274    1.065829  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)\n",
    "\n",
    "# what we did adds 'embed_2d_0' and 'embed_2d_1' columns to the DataFrames in dataset.dfs\n",
    "dataset.dfs[\"raw\"]().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48361052",
   "metadata": {},
   "source": [
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "We are ready for the annotation interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f5ae83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T01:25:44.340365Z",
     "iopub.status.busy": "2023-12-05T01:25:44.339709Z",
     "iopub.status.idle": "2023-12-05T01:25:44.424168Z",
     "shell.execute_reply": "2023-12-05T01:25:44.423592Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.stable import simple_annotator\n",
    "\n",
    "interactive_plot = simple_annotator(dataset)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4bb0c",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface basics</summary>\n",
    "    <details open><summary>Video guide</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WYN2WduzJWg\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide</summary>\n",
    "        There should be a `SupervisableDataset` board on the left and an `BokehDataAnnotator` on the right, each with a few buttons.\n",
    "\n",
    "        === \"SupervisableDataset\"\n",
    "            -   `push`: push `Dataset` updates to the bokeh plots.\n",
    "            -   `commit`: add data entries selected in the `Annotator` to a specified subset.\n",
    "            -   `dedup`: deduplicate across subsets by `feature` (last in gets kept).\n",
    "            -   `export`: save your data (all subsets) in a specified format.\n",
    "\n",
    "        === \"BokehDataAnnotator\"\n",
    "            -   `raw`/`train`/`dev`/`test`: choose which subsets to display or hide.\n",
    "            -   `apply`: apply the `label` input to the selected points in the `raw` subset only.\n",
    "\n",
    "        We've essentially put the data into neighborboods based on the vectorizer, but the quality (homogeneity of labels) of such neighborhoods can vary.\n",
    "\n",
    "        -   hover over any data point to see its tooltip.\n",
    "        -   take advantage of different selection tools to apply labels at appropriate scales.\n",
    "        -   the search widget might turn out useful.\n",
    "            -    note that it does not select points but highlights them.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
