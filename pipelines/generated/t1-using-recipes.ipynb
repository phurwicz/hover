{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5418f1",
   "metadata": {},
   "source": [
    "> The most common usage of `hover` is through built-in `recipe`s like in the quickstart.\n",
    ">\n",
    "> :ferris_wheel: Let's explore another `recipe` -- an active learning example.\n",
    "\n",
    "-   <details open><summary>Dependencies for {== local environments ==}</summary>\n",
    "    When you run the code locally, you may need to install additional packages.\n",
    "\n",
    "    To run the text embedding code on this page, you need:\n",
    "```shell\n",
    "    pip install spacy\n",
    "    python -m spacy download en_core_web_md\n",
    "```\n",
    "\n",
    "    To render `bokeh` plots in Jupyter, you need:\n",
    "```shell\n",
    "    pip install jupyter_bokeh\n",
    "```\n",
    "\n",
    "    If you are using JupyterLab older than 3.0, use this instead ([reference](https://pypi.org/project/jupyter-bokeh/)):\n",
    "```shell\n",
    "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "    jupyter labextension install @bokeh/jupyter_bokeh\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## **Fundamentals**\n",
    "\n",
    "Hover `recipe`s are functions that take a `SupervisableDataset` and return an annotation interface.\n",
    "\n",
    "The `SupervisableDataset` is assumed to have some data and embeddings.\n",
    "\n",
    "## **Recap: Data & Embeddings**\n",
    "\n",
    "Let's preprare a dataset with embeddings. This is almost the same as in the [quickstart](../t0-quickstart/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00506d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T02:12:36.466790Z",
     "iopub.status.busy": "2022-07-24T02:12:36.466265Z",
     "iopub.status.idle": "2022-07-24T02:12:38.167704Z",
     "shell.execute_reply": "2022-07-24T02:12:38.166995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Initializing</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Initializing\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Deduplicating</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Deduplicating\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset raw rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">376</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset raw rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m376\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset train rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">389</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset train rows: \u001b[0m\u001b[1;36m400\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m389\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset dev rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset dev rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m96\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: --subset test rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> -&gt; </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: --subset test rows: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m -> \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Set up label encoder/decoder with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Population updater: latest population with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\"> classes.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Population updater: latest population with \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m classes.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: SupervisableTextDataset: finished initialization.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: SupervisableTextDataset: finished initialization.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hover.core.dataset import SupervisableTextDataset\n",
    "import pandas as pd\n",
    "\n",
    "raw_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_raw.csv\"\n",
    "train_csv_path = \"https://raw.githubusercontent.com/phurwicz/hover-gallery/main/0.5.0/20_newsgroups_train.csv\"\n",
    "\n",
    "# for fast, low-memory demonstration purpose, sample the data\n",
    "df_raw = pd.read_csv(raw_csv_path).sample(400)\n",
    "df_raw[\"SUBSET\"] = \"raw\"\n",
    "df_train = pd.read_csv(train_csv_path).sample(400)\n",
    "df_train[\"SUBSET\"] = \"train\"\n",
    "df_dev = pd.read_csv(train_csv_path).sample(100)\n",
    "df_dev[\"SUBSET\"] = \"dev\"\n",
    "df_test = pd.read_csv(train_csv_path).sample(100)\n",
    "df_test[\"SUBSET\"] = \"test\"\n",
    "\n",
    "# build overall dataframe and ensure feature type\n",
    "df = pd.concat([df_raw, df_train, df_dev, df_test])\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "# this class stores the dataset throught the labeling process\n",
    "dataset = SupervisableTextDataset.from_pandas(df, feature_key=\"text\", label_key=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324d714",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7fdae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T02:12:38.171345Z",
     "iopub.status.busy": "2022-07-24T02:12:38.171011Z",
     "iopub.status.idle": "2022-07-24T02:12:40.835005Z",
     "shell.execute_reply": "2022-07-24T02:12:40.834193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:     [There may be some misunderstanding over terms here...]  I agree.  Quite likely, actually.                                                        [...I believe \"Jesus    only\" originally was in the context of baptism.  These are folks who    believe that baptism should be done with a formula mentioning only    Jesus, rather than Father, Son, and Holy Spirit.  This may have    doctrinal implications, but as far as I know it does not mean that    these folks deny the existence or divinity of the Father.  I'm not the    right one to describe this theology, and in fact I think there may be    several, including what would classically be called monophysite or    Arian (two rather different views), as well as some who have beliefs    that are probably consistent with Trinitarian standards, but who won't    use Trinitarian language because they misunderstand it or simply    because it is not Biblical.  --clh]  Not Biblical?  What then can they make of the end of Matthew?  (28:18)And Jesus came and said to them, \"All authority in heaven and on earth has been given to me. (19)Go therefore and make disciples of all nations, baptizing them in the name of the Father and of the Son and of the Holy Spirit, (20) and teaching them to obey everything that I have commanded to you.  And remember, I am with you always, to the end of the age.\" {Other ancient authorities add *Amen*} [NRSV]  The notes give no sense that this is emended.  Do other texts contradict this regarding Baptism?  Or is a misunderstanding of the Trinity the most likely explanation after all?  But maybe I simply misunderstand their views.  (Is anyone else out there forced to read this group with both a good Bible and an unabridged dictionary??  Christianity really is an education in itself.)  -- ------------------------------------------------------------------------ ------------------------------------------------------------------------  [Arrgggghhhh.  When I talked about people who rejected Trinitarian language as unBiblical, I was speaking of Trinitarian theology, things like \"one essense and three persons\".  Obviously the three-fold baptismal formula is Biblical, as you point out.  (I normally use the term \"three-fold\" in referring to Mat.  While it is certainly consistent with belief in the Trinity, the Trinity is a doctrine whose full formulation occurred in the 4th and 5th Cent's.  It's unlikely that Mat. had in mind the fully-developed Trinitarian doctrine. Indeed the three-fold baptismal formula is used by some groups that do not believe in the Trinity.)  The disagreement over baptismal formulae occurs because of passages such as Acts 2:38, which command baptism in the name of Jesus.  (There are a couple of other passages in Acts as well.)  This leaves us with sort of a problem: we're commanded in Mat. to baptize in the name of the Father, the Son, and the Holy Spirit, and in Acts to baptize in the name of Jesus.  \"Jesus only\" groups baptize in the name of Jesus.  They consider this consistent with Mat 28:18, because they say that Jesus is the name of the Father, the Son, and the Holy Spirit.  I'm not the right one to ask to explain what this means.  I will simply say that it does not appear to be normal Trinitarian theology.  (It is also an odd way of dealing with the idiomatic phrase \"in the name of\".)  Those who use the three-fold formula don't seem to have a standard answer to the passages talking about baptizing in the name of Jesus. I suspect that the most common explanation is to say that \"in the name of\" need not be a verbal formula.  To say that you baptize in the name of Jesus may simply mean that you are doing baptism under Jesus' authority.  In the 1st Cent. context, it contrasts Christian baptism with the baptism of John or other Jewish baptism.  Of course there's a certain parallelism between these passages.  That suggests that we could just as well say that Mat 28:18 doesn't require the specific three-fold formula to be used in baptism, but simply characterizes baptism done by those who follow the Father, Son, and Holy Spirit.  One might well suspect that in the early church, more than one baptismal formula was used.  So long as we consider following Jesus to be the same as following the Father, Son, and Holy Spirit, no great damage would be done by such a difference.  This does *not* mean that I think we should go back to using both formulae.  Baptism is one of the few things that almost all Christian groups now recognize mutually, so I do not think doing something to upset that would be in the interests of the Gospel.  This is reinforced by the fact that those groups that actually use \"in the name of Jesus\" now do seem to have in mind a difference in doctrine.  But as I've said before, I'm not the one to explain what their doctrine is.\n",
      "Vector shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from functools import lru_cache\n",
    "\n",
    "# use your preferred embedding for the task\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# raw data (str in this case) -> np.array\n",
    "@lru_cache(maxsize=int(1e+4))\n",
    "def vectorizer(text):\n",
    "    clean_text = re.sub(r\"[\\s]+\", r\" \", str(text))\n",
    "    return nlp(clean_text, disable=nlp.pipe_names).vector\n",
    "\n",
    "text = dataset.dfs[\"raw\"].loc[0, \"text\"]\n",
    "vec = vectorizer(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Vector shape: {vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd31b6a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70e432e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T02:12:40.839429Z",
     "iopub.status.busy": "2022-07-24T02:12:40.838550Z",
     "iopub.status.idle": "2022-07-24T02:13:03.026857Z",
     "shell.execute_reply": "2022-07-24T02:13:03.026106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 961/961 [00:02<00:00, 428.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">861</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Fit-transforming UMAP on \u001b[0m\u001b[1;36m861\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ðŸ”µ SupervisableTextDataset: Transforming UMAP on </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"color: #000080; text-decoration-color: #000080\"> samples</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mðŸ”µ SupervisableTextDataset: Transforming UMAP on \u001b[0m\u001b[1;36m100\u001b[0m\u001b[34m samples\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ SupervisableTextDataset: Computed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">-d embedding in columns </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_0'</span><span style=\"color: #008000; text-decoration-color: #008000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'embed_2d_1'</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ SupervisableTextDataset: Computed \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m-d embedding in columns \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32m'embed_2d_0'\u001b[0m\u001b[32m, \u001b[0m\u001b[32m'embed_2d_1'\u001b[0m\u001b[1;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# any kwargs will be passed onto the corresponding reduction\n",
    "# for umap: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "# for ivis: https://bering-ivis.readthedocs.io/en/latest/api.html\n",
    "reducer = dataset.compute_nd_embedding(vectorizer, \"umap\", dimension=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a53424",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Recipe-Specific Ingredient**\n",
    "\n",
    "Each recipe has different functionalities and potentially different signature.\n",
    "\n",
    "To utilize active learning, we need to specify how to get a model in the loop.\n",
    "\n",
    "`hover` considers the `vectorizer` as a \"frozen\" embedding and follows up with a neural network, which infers its own dimensionality from the vectorizer and the output classes.\n",
    "\n",
    "-   This architecture named [`VectorNet`](../../reference/core-neural/#hover.core.neural.VectorNet) is the (default) basis of active learning in `hover`.\n",
    "\n",
    "-   <details open><summary>Custom models</summary>\n",
    "    It is possible to use a model other than `VectorNet` or its subclass.\n",
    "\n",
    "    You will need to implement the following methods with the same signatures as `VectorNet`:\n",
    "\n",
    "    -   [`train`](../../reference/core-neural/#hover.core.neural.VectorNet.train)\n",
    "    -   [`save`](../../reference/core-neural/#hover.core.neural.VectorNet.save)\n",
    "    -   [`predict_proba`](../../reference/core-neural/#hover.core.neural.VectorNet.predict_proba)\n",
    "    -   [`prepare_loader`](../../reference/core-neural/#hover.core.neural.VectorNet.prepare_loader)\n",
    "    -   [`manifold_trajectory`](../../reference/core-neural/#hover.core.neural.VectorNet.manifold_trajectory)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb255f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T02:13:03.030786Z",
     "iopub.status.busy": "2022-07-24T02:13:03.030144Z",
     "iopub.status.idle": "2022-07-24T02:13:03.047277Z",
     "shell.execute_reply": "2022-07-24T02:13:03.046618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ðŸŸ¢ VectorNet: reset neural net: in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span><span style=\"color: #008000; text-decoration-color: #008000\"> out </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mðŸŸ¢ VectorNet: reset neural net: in \u001b[0m\u001b[1;36m300\u001b[0m\u001b[32m out \u001b[0m\u001b[1;36m20\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.6023646e-02 5.5775890e-04 1.7057775e-01 2.7073735e-01 3.8581172e-01\n",
      " 1.0228526e-03 3.9507754e-04 2.2278021e-03 5.5046024e-04 4.3535647e-03\n",
      " 6.9209905e-03 6.0708622e-05 2.2462802e-03 1.7282596e-02 4.6559834e-04\n",
      " 2.9141307e-03 1.0070576e-03 5.2443009e-02 8.7414827e-04 3.5274450e-03]\n",
      "[[7.6023646e-02 5.5775890e-04 1.7057775e-01 2.7073735e-01 3.8581172e-01\n",
      "  1.0228526e-03 3.9507754e-04 2.2278021e-03 5.5046024e-04 4.3535647e-03\n",
      "  6.9209905e-03 6.0708622e-05 2.2462802e-03 1.7282596e-02 4.6559834e-04\n",
      "  2.9141307e-03 1.0070576e-03 5.2443009e-02 8.7414827e-04 3.5274450e-03]]\n"
     ]
    }
   ],
   "source": [
    "from hover.core.neural import VectorNet\n",
    "from hover.utils.common_nn import LogisticRegression\n",
    "\n",
    "# Create a model with vectorizer-NN architecture.\n",
    "# model.pt will point to a PyTorch state dict (to be created)\n",
    "# the label classes in the dataset can change, and vecnet can adjust to that\n",
    "vecnet = VectorNet(vectorizer, LogisticRegression, \"model.pt\", dataset.classes)\n",
    "\n",
    "# predict_proba accepts individual strings or list\n",
    "# text -> vector -> class probabilities\n",
    "# if no classes right now, will see an empty list\n",
    "print(vecnet.predict_proba(text))\n",
    "print(vecnet.predict_proba([text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a10c63",
   "metadata": {},
   "source": [
    "Note how the callback dynamically takes `dataset.classes`, which means the model architecture will adapt when we add classes during annotation.\n",
    "\n",
    "## :sparkles: **Apply Labels**\n",
    "\n",
    "Now we invoke the `active_learning` recipe.\n",
    "\n",
    "-   <details open><summary>Tips: how recipes work programmatically</summary>\n",
    "    In general, a `recipe` is a function taking a `SupervisableDataset` and other arguments based on its functionality.\n",
    "\n",
    "    Here are a few common recipes:\n",
    "\n",
    "    === \"active_learning\"\n",
    "\n",
    "        ::: hover.recipes.experimental.active_learning\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"simple_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.simple_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    === \"linked_annotator\"\n",
    "\n",
    "        ::: hover.recipes.stable.linked_annotator\n",
    "            rendering:\n",
    "              show_root_heading: false\n",
    "              show_root_toc_entry: false\n",
    "\n",
    "    The recipe returns a `handle` function which `bokeh` can use to visualize an annotation interface in multiple settings.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1bf126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T02:13:03.050718Z",
     "iopub.status.busy": "2022-07-24T02:13:03.050104Z",
     "iopub.status.idle": "2022-07-24T02:13:03.102708Z",
     "shell.execute_reply": "2022-07-24T02:13:03.102001Z"
    }
   },
   "outputs": [],
   "source": [
    "from hover.recipes.experimental import active_learning\n",
    "\n",
    "interactive_plot = active_learning(dataset, vecnet)\n",
    "\n",
    "# ---------- NOTEBOOK MODE: for your actual Jupyter environment ---------\n",
    "# this code will render the entire plot in Jupyter\n",
    "# from bokeh.io import show, output_notebook\n",
    "# output_notebook()\n",
    "# show(interactive_plot, notebook_url='https://localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b792f5d",
   "metadata": {},
   "source": [
    "-   <details open><summary>Tips: annotation interface with multiple plots</summary>\n",
    "    <details open><summary>Video guide: leveraging linked selection</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TIwBlCH9YHw\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Video guide: active learning</summary>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hRIn3r7ovQ8\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "    </details>\n",
    "\n",
    "    <details open><summary>Text guide: active learning</summary>\n",
    "        Inspecting model predictions allows us to\n",
    "\n",
    "        -   get an idea of how the current set of annotations will likely teach the model.\n",
    "        -   locate the most valuable samples for further annotation.\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
